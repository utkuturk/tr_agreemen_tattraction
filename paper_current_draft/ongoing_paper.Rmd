---
title             : "Agreement Attraction in Turkish"
shorttitle        : "Agreement Attraction in Turkish"
author: 
  - name          : "Utku Turk"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "utku.turk@boun.edu.tr"
  - name          : "Pavel Logacev"
    affiliation   : "1"
affiliation:
  - id            : "1"
    institution   : "Boğaziçi University University, Istanbul, Turkey"
authornote: |
  authornote
abstract: |
  We report the results of two speeded acceptability judgment experiments in Turkish. We hypothesized an alternative explanation for agreement attraction effects in Turkish that is based on shallow processing. Our findings contradict our hypothesized form-driven processing strategy and support an account of agreement attraction based on the use of abstract linguistic features, rather than mere form.
keywords          : "keywords"
wordcount         : "X"
bibliography      : ["new-references.bib","r-references.bib"]
floatsintext      : yes
figurelist        : no
tablelist         : no
numbersections    : yes
geometry          : left=25mm, right=25mm, top=25mm, bottom=25mm
#fontsize          : 10pt
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no
documentclass     : "apa6"
classoption       : "doc"
output:
  papaja::apa6_pdf:
    latex_engine: xelatex
    includes:
        in_header: paper_draft_preamble.tex
editor_options: 
  chunk_output_type: console
keep_tex: TRUE
keep_md: TRUE
---

```{r setup, eval =T, include = FALSE, message=FALSE, warning=FALSE}
library("papaja")
library(knitcitations)
library(tidyverse)
library(magrittr)
library(ggplot2)
theme_set(theme_bw())

library(car, warn.conflicts = FALSE)
library(MASS)
library(brms)
library(xtable)
library(ggpubr)

library(languageR)
library(tidyverse)
library(gdata)
library(MASS)
library(magrittr)
library(ggplot2)

source("../scripts/misc.R")

```

```{r analysis-preferences, eval =T, message=FALSE, warning=FALSE}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(encoding = 'UTF-8',
                      cache.extra = knitr::rand_seed,
                      echo = FALSE,
                      results = 'asis')
options("citation_format" = "pandoc")

```

# Introduction

It has been observed that speakers often fail to accurately process grammatical dependencies between the parts of a sentence [@GibsonThomas:1999; @PhillipsEtAl:2011]. 
For example, ungrammatical center-embedded structures like  *The patient who the nurse who the clinic had hired met Jack* are found grammatical by native English speakers. 
One such comprehension error is agreement attraction [@Nicoletal:1997; @PearlmutterGarnseyBock:1999; @WagersEtAl:2009]. 
Speakers may erroneously find sentences acceptable in which the verb erroneously agrees with a syntactically unrelated noun phrase (*the attractor*) instead of the subject (*the agreement controller*) as in \@ref(item:wagers2009).

\begin{exe}
\ex \label{item:wagers2009} * The key to the cells are rusty from many years of disuse. 
\end{exe}

<!-- for some reason I could not add citation in the examples. \hfill \footnotesize{[@WagersEtAl:2009]} -->  

These effects were found to be robust in a variety of constructions in different languages, e.g. English , German , Russian, Arabic, Spanish, Armenian, Slovak, Greek, and Turkish [@LagoEtAl2018; @LagoEtAl:2015; @ReifegersteEtAl:2016; @BadeckerKuminiak:2007; @TuckerEtAl:2015; @PaspaliMarinis:2020; @AvetisyanEtAl:2020] using structures like object relative clauses, subject relative clauses, possessive relative clauses, and genitive-possessive noun phrases [@LagoEtAl2018; @WagersEtAl:2009; @LagoEtAl:2015; @FranckColonnaRizzi:2015; @TuckerEtAl:2015; @ParkerEtAl:2015; @Dillon2013a; @Haussler2009]. These effects are found both in grammatical marking of the gender and the number [@BadeckerKuminiak:2007; @Slioussar:2016; @PaspaliMarinis:2020], and attested with various methods including maze tasks, ERP, eye tracking to name a few [@TannerEtAl:2014; @WagersEtAl:2009; @Nicoletal:1997]. 

One instance of agreement attraction is found in the production processes in which participants were asked to complete sentence fragments [@Bock1991]. Participants used the wrong verb more often when the attractor (*cabinets*) were plural, and the agreement controller (*key*) were singular as in \@ref(item:bock1991).

\begin{exe}
\ex The key to the cabinets \ldots 
\label{item:bock1991}
\end{exe}

Agreement attraction is also found in the comprehension studies. In these studies, agreement attraction is found either as a facilitation in reading times or as a effect in the acceptability rates [@WagersEtAl:2009]. 
When reading times are checked, they found that the participants read the ungrammatical sentences with a plural attractor easier then the ungrammatical sentences without a plural attractor. 
Similarly, participants found ungrammatical sentences with a plural attractor acceptable more often than that of with a singular attractor.

Some theories [@EberhardEtAl:2005; @HammerlyEtAl:2019] explain this phenomenon through a faulty representation of the number on the head of the agreement controller whereas other theories assume that agreement attraction is due to an error in the access to the number of the agreement controller [@WagersEtAl:2009; @NicenboimEtAl:2018]. 

Agreement attraction effects can equally well be explained by assuming shallow processing. Recent studies in psychology literature show that in certain environments people may not notice ungrammaticalities in a sentence or may not compute dependencies in a sentence completely [@OteroKintsch:1992; @FerreiraBaileyFerraro:2002]. 

To investigate this possibility, we report two speeded acceptability judgment experiments in this paper. The first one inspects the recent @LagoEtAl2018 findings. They found number attraction effects in genitive-possessive constructions such as `_[[the child's] toy]_' ([[_çocuğ-un\textsubscript{Gen}_] _oyuncağ-ı\textsubscript{Poss}_]). They justify the use of this construction with the findings of @NicolEtAl:2016. Since the genitive case is a possible subject marker, the participants can consider genitive marked attractors a candidate for the agreement controller. However, case marking on all subject heads is locally ambiguous the accusative and the possessive. In our experiment 1, we disambiguate the subject head and test whether or not the results were due to the shallow processing of the head subject and sticking with the accusative marked representation under some conditions.

In experiment 2, we test whether or not the agreement attraction effects in Turkish are due to form-driven processing strategy. Instead of processing the whole sentence, participants develop a mental shortcut, matching the form-identical number marking on the attractor and the matrix verb in the Turkish case, specific to the task in hand. We used the verbs of the object relative clauses as an attractor and speculated that if the participants are using the mentioned task-specific strategy, we would see comparable agreement attraction effects.

This paper is organized as \ldots 

# Theories of agreement attraction

The difference between the theories that explain the agreement attraction phenomenon lies in the assumption regarding the origin of the illusion. Some theories [@BockEberhard:1993; @ViglioccoEtAl:1995; @Eberhard:1997; @FranckEtAl:2002; @BergenGibson:2012] explain this phenomenon by hypothesizing that the representations formed from the linguistic input is faulty. One theory in this group is Marking and Morphing Theory. MMT suggests that the subject phrase can hold a continuous number value from 1 (unambiguously plural) to -1 (unambiguously singular). This value is affected by the _percolation_ of the grammatical feature which can happen in any direction. The implementation of such models suggests that the final number of the phrase depends on the number morphology on the head and the elements within the phrase, and the syntactic proximity of these elements to the root node of the phrase. 

Another type of model within this family is based on the idea that linguistic input is noisy, and it is accompanied by a priori linguistic knowledge [@BergenGibson:2012]. This account is an extension of the noisy channel model proposed by @Levy2008, which uses Bayesian inference to model the participants' inference given the word string. @PatsonHusband:2016 provide additional evidence for this type of analysis by showing that final interpretations of agreement attraction cases are not based on the actual string, meaning that the participants infer a plural-marked head noun whereas it is not marked by any plural inflection.

On the other side, some theories assume that agreement attraction is due to an error in the access to the number of the agreement controller [@WagersEtAl:2009; @NicenboimEtAl:2018]. Unlike MMT, these models do not assume an erroneous representation to form. Rather, the agreement attraction effects surface when there is a feature interference in the ungrammatical sentences like \@ref(item:wagers2009). This interference is triggered due to the partial match between the sought retrieval cues and the ones within the subject phrase. On some occasions, when there is no single item matching the necessary cues from the verb, number related matching cue from the attractor may satisfy the retrieval. 

# Agreement Attraction in Turkish

Recently, @LagoEtAl2018 demonstrated comparable agreement attraction effects in comprehension with Turkish stimuli. 
They used the speeded acceptability judgment method with the following question that asks participants whether or not the sentence sounded acceptable. 
They used sentences like (\@ref(item:LagoExp))\footnote{Abbreviations used in the paper are as follows: \printglossaries} with genitive-marked attractors.
They manipulated the number morphology on the attractor (plural x singular) and the grammaticality of the verb (grammatical (SG) x ungrammatical (PL)). The example given here represents all four conditions.  
In an ungrammatical condition with a plural attractor, the word _ressamların_ (painters') is expected to create a grammaticality illusion and mistaken for the agreement controller instead of the head subject _rakibi_ (rival\textsubscript{poss}). 

\begin{exe}
\ex \label{item:LagoExp}
\gll Ressam-$\emptyset$/lar-(n){\i}n rakib-i at\"{o}lye-den h{\i}zla uzakla\c{s}-t{\i}-$\emptyset$/lar.\\
painter-\Sg{}/\Pl{}-\Gen{} rival-\Poss{} workshop-\Abl{} quickly walked.away-\Pst{}-\Sg{}/\Pl{}\\
\glt `The painter's/painters' rival walked\textsubscript{sg/pl} away from the workshop quickly.'
\end{exe}

Following previous work on agreement attraction, they
argue
that non-intervening genitive marked attractor may create grammaticality illusions in Turkish. They base their argument on the inhibition constraint proposed by @NicolEtAl:2016. @NicolEtAl:2016 show in a production experiment that genitive attractors do not trigger grammaticality illusions. According to their hypothesis, the reason behind their results is the fact that the participants may never consider genitive-marked NPs as a potential candidate for subjects.
However, this is not the case in Turkish. In embedded sentences, the definite subject is always marked with the genitive case, which makes the genitive-marked NPs a candidate for the subjecthood in Turkish. 

However, a potential complication in interpreting these results is the fact that all head nouns in Lago et al.'s stimuli were morphologically ambiguous between possessive and accusative case. This ambiguity is the result of the consonant-ending subject head usage. In Turkish, both the accusative case and the possessive surface as -I. \footnote{Throughout the paper, we present the archiphonemes with the capitalized form of the symbol. The suffix -I can surface as \textit{-i, -ı, -u, -ü}. }
Because of this local ambiguity, all experimental sentences have two possible parses up until to the end of the sentence. Check the following examples in \@ref(parse:LagoExpAcc) and \@ref(parse:LagoExpPoss).

\begin{exe}
\ex \label{parse:LagoExpAcc}
\gll [\textsubscript{CP}[\textsubscript{CP}Ressam-lar-{\i}n rakib-i at\"{o}lye-den h{\i}zla uzakla\c{s}-t{\i}ğ-{\i}n-{\i}] bil-iyor-um.]\\
painter-\Pl{}-\Gen{} rival-\Acc{} workshop-\Abl{} quickly walked.away-\Nmlz{}-\Poss{}-\Acc{} know-\Prog{}-\Fsg{}.\\
\glt `I know that the painters' rival walked away from the workshop quickly.'
\ex \label{parse:LagoExpPoss}
\gll [\textsubscript{CP}Ressam-lar-{\i}n rakib-i at\"{o}lye-den h{\i}zla uzakla\c{s}-t{\i}.]\\
painter-\Pl{}-\Gen{} rival-\Poss{} workshop-\Abl{} quickly walked.away-\Pst.\Tsg{}.\\
\glt `the painters' rival walked away from the workshop quickly.'
\end{exe}

The local ambiguity between the accusative and the possessive is not resolved until the verb _uzaklaştı_. Regardless of the assumption for parallel or serial processing, there may exist certain conditions where participants are stuck with a rival-\Acc{} representation. Since accusative number agreement controllers are extremely rare, while genitive agreement controllers are very frequent in Turkish, the ambiguity of the head noun may occasionally render the genitive modifier a stronger contender for being the agreement controller, resulting in agreement attraction. The problem with such cases for the Inhibition hypothesis is that it is not clear whether the possible non-subjecthood clue from the accusative case plays a role or the possible subjecthood clue from the genitive case plays a role. 


# Experiment 1


```{r Exp1:DataWrangling, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

fname_data <- "../workspace_exp1/exp_data.rds"
data_exp1 <- readRDS(fname_data)
fname_form <- "../workspace_exp1/exp_form.rds"
form_exp1 <- readRDS(file = fname_form)

### note: the low accuracy on fillers is not caused by a couple of items
###       -> see below
# filler_avgs <- 
# data_exp1 %>% subset(Type == "filler") %>% group_by(Item, condition) %>% 
#               summarize(M = mean(ResponseYes, na.rm = T)) %>%
#               arrange(condition, Item)
# fillers %>% subset(condition == "a") 
# fillers %>% subset(condition == "b")
###

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj <- data_exp1 %>%
                group_by(subject, experiment, condition, 
                         grammatical, verb_num, attractor_num) %>%
                summarize(avRT = mean(RT), 
                          p_yes = mean(ResponseYes, na.rm = T), 
                          N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_wide <- avg_by_subj %>% 
                      mutate(expcond = paste(experiment, condition, sep="_")) %>% 
                      ungroup() %>%
                      dplyr::select(-experiment, -condition, -avRT, -N,
                                    -grammatical, -verb_num, -attractor_num) %>%
                      tidyr::spread(expcond, p_yes) %>% 
                      mutate(delta_dc = AgrAttr_d - AgrAttr_c)

# Load Lago et al.'s monolingual data
fname_lagoetal <- "../Data/Lago_et_al/Lago_data.csv"
df_lagoetal <- read.csv(fname_lagoetal, encoding = "UTF-8", as.is = T)
df_lagoetal %<>% subset(Group == "monolingual")
df_lagoetal %<>% dplyr::select(-Accuracy, -L1:-Group, -List:-SelfRateGerman)

# Note: All rows with Experiment == "offline" also seem to be for 
#       the UNP task ('Grammatical' is NA). I wonder if these were
#       the same subjects, or if the subject labels were simply the same
#       for the two experiments.
with(df_lagoetal, stopifnot( is.na(Grammatical) == (Experiment == "offline") ))

df_lagoetal_unp <- df_lagoetal %>% 
                    subset(is.na(Grammatical)) %>%
                    dplyr::select(-Grammatical:-Label)
df_lagoetal_attr <- df_lagoetal %>% 
                  subset(!is.na(Grammatical)) %>%
                  dplyr::select(-Distance:-NewCond)

df_lagoetal_attr %<>% mutate(ResponseYes = (Response == "yes") ) %>% 
                      dplyr::select(-Response)
df_lagoetal_attr %<>% ungroup() %>%
                      dplyr::select(grammatical=Grammatical,
                                    attractor_num=Attractor,
                                    experiment=Experiment,
                                    lagoetal_condition=Condition, 
                                    subject=Participant, 
                                    item=Item,
                                    ResponseYes,
                                    RT)

# map to our condition labels
lagoetal_condition_mapping <- data.frame( condition = c("a", "b", "c", "d"),
                                          lagoetal_condition = c("d", "b", "c", "a"), 
                                          stringsAsFactors = F)
df_lagoetal_attr %<>% left_join( lagoetal_condition_mapping, by = "lagoetal_condition" )

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj_lagoetal <- df_lagoetal_attr %>%
                            group_by(subject, experiment, condition, grammatical, attractor_num) %>%
                            summarize(avRT = mean(RT), 
                                      p_yes = mean(ResponseYes, na.rm = T), 
                                      N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_lagoetal_wide <- avg_by_subj_lagoetal %>% 
                                    mutate(expcond = paste(experiment, condition, sep="_")) %>% 
                                    ungroup() %>%
                                    dplyr::select(-experiment, -condition, -avRT, -N,
                                                  -grammatical, -attractor_num) %>%
                                    tidyr::spread(expcond, p_yes) %>% 
                                    mutate(delta_dc = online_d - online_c)


# identify bad participants 
bad_subjects <- subset(avg_by_subj_wide, delta_dc <= 0.25 ) %>% .$subject
data_exp1_clean <- data_exp1 %>% subset(!subject %in% bad_subjects)

data_exp1_clean %<>% filter( RT > 200)

# identify bad participants 
bad_subjects_lagoetal <- subset(avg_by_subj_lagoetal_wide, delta_dc <= 0.25 ) %>% .$subject
df_lagoetal_attr_clean <- df_lagoetal_attr %>% subset(!subject %in% bad_subjects_lagoetal)

df_lagoetal_attr_clean %<>% filter( RT > 200)

# merge both datasets
df_merge_exp1 <- data_exp1_clean %>% ungroup() %>% 
                      dplyr::select(source=experiment, 
                                    grammatical, 
                                    attractor_num,
                                    # condition,
                                    subject, 
                                    item=Item,
                                    ResponseYes, 
                                    RT)
df_merge_exp1$experiment <- "Experiment 1"
df_merge_exp1$grammatical %<>% dplyr::recode(gram="grammatical", ungram="ungrammatical")
df_merge_exp1$attractor_num %<>% dplyr::recode(pl="plural", sg="singular")

df_merge_exp1$item %<>% as.integer()
df_merge_exp1$subject %<>% as.character()



df_merge_lago <- df_lagoetal_attr_clean %>%
                      ungroup() %>% 
                      dplyr::select(grammatical, attractor_num,
                                    subject, item, ResponseYes, RT)
df_merge_lago$experiment <- "Lago et al. (2018)" 
df_merge_lago$source <- NA

```

```{r Exp1:wordFreq, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
# word frequencies: 
# Utku: are these still relevant for us? 

word_freq <- readxl::read_excel("../Data/frequencies_exp1_and_lago.xlsx", sheet = 1)
word_freq$freq_percentage %<>% as.numeric()
word_freq %<>% dplyr::select(-freq_standardized, -freq_percentage, -word)
word_freq %<>% tidyr::spread(place, freq_count)

word_freq %<>% dplyr::group_by(exp) %>% 
               dplyr::mutate( freq_cat_n1 = ifelse(n1 > median(n1), "high", "low"),
                              freq_cat_n2 = ifelse(n2 > median(n2), "high", "low"),
                              freqlog_n1 = scale(log(n1)),
                              freqlog_n2 = scale(log(n2)),
                              freqlog_n1n2 = log(n1) - log(n2)
                            ) %>% 
                ungroup()
# word_freq$freq_cat_n1 %<>% as.factor()
# word_freq$freq_cat_n2 %<>% as.factor()


word_freq_exp1 <- word_freq %>% subset(exp == "exp1") %>% dplyr::select(-exp)
df_merge_exp1 %<>% left_join(word_freq_exp1, by = "item")

word_freq_lago <- word_freq %>% subset(exp == "lagoetal") %>% dplyr::select(-exp)
df_merge_lago %<>% left_join(word_freq_lago, by = "item")
df_merge_lago$item %<>% add(1000)

df_merged <- dplyr::bind_rows(df_merge_exp1, df_merge_lago)
df_merged$subject %<>% as.factor()
df_merged$item %<>% as.factor()
```

Previous work in agreement attraction found significant effects in comprehension using forced-choice acceptability judgment tasks [@HammerlyEtAl:2019; @LagoEtAl2018; @WagersEtAl:2009]. The goal of experiment 1 is to control for the effect of head noun ambiguity on the magnitude of agreement attraction effect. To this end, we replicated @LagoEtAl2018 experiment with unambiguous head nouns. We disambiguated the cases by using vowel-ending head nouns. When attached to a vowel-ending noun, the accusative case and the possessive surface with a different floating consonant. For example, we changed sentence (\@ref(item:LagoExpContrast)) to sentence (\@ref(item:OurExpContrast)). 

\begin{exe}
\ex \label{item:LagoExpContrast}
\gll Şarkıcı-$\emptyset$/lar-(n)ın vokalist-i sahne-de sürekli zıpla-dı-$\emptyset$/lar.\\
singer-\Sg{}/\Pl{}\Gen{} vocalist-\Poss{} stage-\Loc{} non-stop jump-\Pst{}-\Sg{}/\Pl{}\\
\glt `The singer's/singers' backup vocalist jumped\textsubscript{sg/pl} on the stage non-stop.'

\ex \label{item:OurExpContrast}
\gll Yönetici-$\emptyset$/ler-(n)in aşçı-sı mutfak-de sürekli zıpla-dı-$\emptyset$/lar.\\
manager-\Sg{}/\Pl{}\Gen{} cook-\Poss{} kitchen-\Loc{} non-stop jump-\Pst{}-\Sg{}/\Pl{}\\
\glt `The manager's/managers' cook jumped\textsubscript{sg/pl} in the kitchen non-stop.'
\end{exe}


We hypothesized that if the morpho-phonological ambiguity, thus the Inhibition from the accusative case, was a key factor in agreement attraction in Turkish, resolving it should diminish the attraction affects. This would tell us that readers may indeed get affected by local ambiguities which may serve as a supporting point for shallow processing. 


## Participants

We recruited 118 undergraduate students to participate in Experiment 1 in exchange for course credit. All participants were native speakers of Turkish, with an average age of `r printnum(mean(form_exp1$Age))` (range: `r min(form_exp1$Age)` -- `r max(form_exp1$Age)`).  
Experiment were carried out following the Declaration of Helsinki and the regulations concerning ethics at research in Bo\u{g}azi\c{c}i University. All participants provided informed consent prior to their participation.

## Materials

We used 40 sets of sentences like \@ref(item:exp1ExperimentalItems), in which we manipulated 
(i) the number of the attractor noun, and
(ii) the number agreement on the verb. 
Plural number and plural agreement were both marked with the affix \textit{-ler/-lar}, while singular number and singular agreement were marked with its absence. 
We have used the experimental items in @LagoEtAl2018 as a base. 
All sentences started with a complex subject NP like \textit{`the manager's cook'} (\textit{yöneticinin aşcısı}), in which the possessor, which functioned as the attractor, carried genitive case, and the head noun carried unambiguous possessive case. 
Because the head noun was singular in all conditions, sentences with plural verb agreement were ungrammatical. 
Moreover, as in the original study, the properties of the nouns in the complex subject NP and the relation between these nouns held constant in our replication. 
The distribution of the verb types followed the same pattern as in @LagoEtAl2018, namely twenty unergatives, eighteen unaccusatives, and two optionally transitive verbs. 
Both in @LagoEtAl2018 and in our replication, pre-verbal adverbials consisting of 2-3 words (15 characters on average) are used. We changed this adverbials for plausability reasons, such that with head nouns like cooks we used locational adverbs like kitchen, instead of the stage.
Unlike the @LagoEtAl2018 sentences, our head nouns were vowel-ending, and therefore not ambiguous between accusative case, for which the case suffix is \textit{-yI}, and possessive case, for which the suffix is \textit{-sI}. 

\begin{exe}
\ex \label{item:exp1ExperimentalItems}
  \begin{xlist}

  \ex \textsc{Plural Attractor, Ungrammatical (Plural Verb)} \label{item:exp1expitem-plpl} 
  \gll *[Yönetici-ler-in \textbf{aşcı-sı}] mutfak-ta sürekli \textbf{zıpla-dı-lar}.\\ 
  manager-\textsc{pl}-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`The cooks of the manager were jumping in the kitchen non-stop.'}

\ex \textsc{Plural Attractor, Grammatical (Singular Verb)} \label{item:exp1expitem-plsg} 
  \gll [Yönetici-ler-in \textbf{aşcı-sı}] mutfak-ta sürekli \textbf{zıpla-dı}.\\ 
  manager-\textsc{pl}-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{pst}.\\
  \glt \textit{`The cooks of the manager was jumping in the kitchen non-stop.'}

\ex \textsc{Singular Attractor, Ungrammatical (Plural Verb)} \label{item:exp1expitem-sgpl} 
  \gll *[Yönetici-nin \textbf{aşcı-sı}] mutfak-ta sürekli \textbf{zıpla-dı-lar}.\\ 
  manager-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`The cook of the manager were jumping in the kitchen non-stop.'}

\ex \textsc{Singular Attractor, Grammatical (Singular Verb)}\label{item:exp1expitem-sgsg}
  \gll [Yönetici-nin \textbf{aşcı-sı}] mutfak-ta sürekli \textbf{zıpla-dı}. \\ 
  manager-\textsc{gen}  cook-\textsc{poss} kitchen-\textsc{loc} non-stop  jump-\textsc{pst}.\\
  \glt \textit{`The cook of the manager was jumping in the kitchen non-stop.'}
  \end{xlist}
\end{exe}


We intermixed our experimental sentences with 40 filler sentences of two types, as illustrated in \@ref(item:exp1FillerItems). 
To compensate for the fact that among experimental sentences, all ungrammatical sentences ended in a plural-agreeing verb, while all grammatical sentences ended in a singular-agreeing verb, we included 20 grammatical sentences with plural verbs, and 20 ungrammatical sentences with singular agreement. 
This was done in order to discourage participants from using a strategy based on verb number. 
Filler items followed a similar template in which sentence again started with a complex genitive-possessive noun phrase. 
However, in filler items, they were the controller of an embedded clause which serves as a adverbial. 
In grammatical fillers, we have made use of pro-dropped subject strategy in Turkish; thus, it enabled us to use plural verb without having ungrammatical sentences as in \@ref(item:exp1GrammaticalFiller). The object \textit{tutarsızlık} is a bare nominal preceding a light verb construction. 
Differently in ungrammatical fillers, bare nominal did not precede a light verb construction, but an adverb and a verb. Since Turkish only allows bare nominals right next to the verb, sentences were deemed ungrammatical when the participants read the verb. 

\begin{exe}
\ex \label{item:exp1FillerItems}
\begin{xlist}
\ex \textsc{Grammatical Filler (Plural Verb)} \label{item:exp1GrammaticalFiller}
\gll [Sosyolog-un \textbf{öğrenci-si}] konuş-unca tutarsızlık açığ-a \textbf{çıkar-dı-lar}.\\ 
sociolog-\textsc{gen}  student-\textsc{poss} speak-\textsc{nmlz} inconsistency  open-\textsc{dat} deduct-\textsc{pst}-\textsc{pl}.\\
\glt \textit{`When the student of the sociologist spoke, they revealed an inconsistency.'}

\ex \textsc{Ungrammatical Filler (Singular Verb)}
\gll *[Dansöz-ün \textbf{koca-sı}] var-ınca kapı sakince \textbf{aç-tı}. \\
dancer-\textsc{gen}  husband-\textsc{poss} arrive-\textsc{nmlz} door slowly  open-\textsc{pst}.\\
\glt \textit{Intended:`When the husband of the dancer came, the door opened slowly.'}
\end{xlist}
\end{exe}

## Procedure

The experiment was run online, using the web-based platform Ibex Farm (\url{http://spellout.net/ibexfarm/}). Each experimental session took approximately 25 minutes to complete.

Prior to the start of the experiment, participants provided demographic information, as well as informed consent to participate in the experiment. They read the instructions, and were given 9 practice trials before the experiment began.

Each trial began with a blank screen for 600 ms, followed by a word-by-word RSVP presentation of the sentence in the center of the screen, followed by an acceptability judgment. 
Sentences were presented word-by-word in 30pt font size, and at a rate of 400 ms per word. Between each word, participants saw a blank screen for 100 ms. Participants pressed the key 'P' for \textit{'acceptable'} and 'Q' for \textit{'unacceptable'}. They were instructed to provide an acceptability rating before the 5,000 ms deadline. During the experiment, they were reminded to respond faster if they responded too slowly. 

Participants saw 40 experimental and 40 filler sentences. Experimental sentences were distributed among four different lists according to a Latin-square design. Every participant saw one version of the experiment with a specific list and one item per condition.   

## Analysis

Since our aim was to test whether the morphological ambiguity present in the @LagoEtAl2018 items affected the presence or magnitude of the agreement attraction effect, statistically, we needed to test for the presence of an interaction between
(i) the presence of the morphological ambiguity on the head noun, and 
(ii) the agreement attraction effect. 
In order to do so, we decided to analyze the data from the present experiment together with Lago et al.'s data, using experiment as an additional factor in the analysis.

Prior to analysis we removed the data for all participants who failed to show sufficient sentitivity to the effect of grammaticality in singular attractor conditions, i.e., when no agreement attraction was expected. Specifically, we removed all participants for whom the difference in the percentage of 'yes' responses between the grammatical condition \@ref(item:exp1expitem-sgsg) and the ungrammatical condition \@ref(item:exp1expitem-sgpl) was below the threshold of 25 percentage points. As a result, we excluded `r length(bad_subjects)` participants from experiment 1, and `r stopifnot(length(bad_subjects_lagoetal) == 1)` one participant from the Lago et al. data

We used the R packages brms [@brms] and rstan [@stan] to fit Bayesian hierarchical models [e.g., @GelmanHill2007]. We analyzed only experimental sentences, and used 
(i) grammaticality of the sentence, 
(ii) attractor number, and 
(iii) presence of morphological ambiguity (i.e., experiment), as well as all their interactions as predictors. 
Moreover, we used by-participant and by-item intercepts and slopes for all predictors.
Data for experiment 1, along with our analysis scripts can be found in \url{https://github.com/utkuturk/replication_lagoetal2018}.


## Results

```{r Exp1:PreparePlots, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
df_exp1_na_nofillers <- subset(df_merge_exp1, is.na(ResponseYes) & source != "filler")
df_merged %<>% subset( !is.na(ResponseYes) )

df_merged %<>% mutate(ResponseCorrect = (ResponseYes == (grammatical == "grammatical") ) )
df_merged_nonna <- df_merged %>% subset(!is.na(ResponseYes))

# avg_clean <- 
# df_merged %>% subset(experiment == "Lago et al. (2018)") %>%
#      group_by(experiment, source, grammatical, attractor_num, subject) %>%
#      summarize(p_yes = mean(ResponseYes, na.rm=T)) %>%
#      summarize(p_yes = mean(p_yes))

avg_clean <- list()
avg_clean$resp <- df_merged_nonna %>% 
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = ResponseYes, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = TRUE)
})

avg_clean$rt <- df_merged_nonna %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

avg_clean$rt_correct <- df_merged_nonna %>% subset(ResponseCorrect) %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

avg_exp <- avg_clean %>% lapply(function(df) { df %>% subset(is.na(source) | source != "filler") })
avg_fillers <- avg_clean %>% lapply(function(df) { df %>% subset(source == "filler") })


pd <- position_dodge(0.0)
p_avg_resp <- avg_exp$resp %>%
              ggplot(aes(grammatical, M, #linetype = attractor_num, 
                         color = attractor_num, group = attractor_num)) + 
                geom_point(position = pd) + geom_line(position = pd) + 
                facet_wrap(~experiment)

p_avg_resp <- p_avg_resp + geom_errorbar(aes(ymin = M - 1.96*SE, ymax = M + 1.96*SE), width = 0.1, position = pd)

# p_avg_resp <- p_avg_resp + geom_line(data = avg_fillers) + 
#                             geom_point(data = avg_fillers) + 

p_avg_resp <- p_avg_resp + theme( strip.background = element_rect(fill="white") ) +
                           theme_bw() + xlab("") + ylab("Percentage 'acceptable'")
p_avg_resp <- p_avg_resp + scale_y_continuous(labels=scales::percent)#, breaks = c(0, .25, .5, .75, 1))
p_avg_resp <- p_avg_resp + theme_bw()
p_avg_resp <- p_avg_resp + scale_color_discrete(name = "Attractor Number")

avg_exp_resp_exp1 <- avg_exp$resp %>% subset(experiment == "Experiment 1")
avg_exp_resp_lagoetal <- avg_exp$resp %>% subset(experiment == "Lago et al. (2018)")
```

```{r Exp1:PrepareTextInputs, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
exp1_cur_entry1 = avg_exp$resp %>% filter(experiment == "Experiment 1", grammatical == "ungrammatical", attractor_num == "plural")
exp1_cur_entry2 = avg_exp$resp %>% filter(experiment == "Experiment 1", grammatical == "ungrammatical", attractor_num == "singular")

exp1_cur_entry3 = avg_exp$resp %>% filter(experiment == "Experiment 1", grammatical == "grammatical", attractor_num == "singular")
exp1_cur_entry4 = avg_exp$resp %>% filter(experiment == "Experiment 1", grammatical == "grammatical", attractor_num == "plural")

lago_cur_entry1 = avg_exp$resp %>% filter(experiment == "Lago et al. (2018)", grammatical == "ungrammatical", attractor_num == "plural")
lago_cur_entry2 = avg_exp$resp %>% filter(experiment == "Lago et al. (2018)", grammatical == "ungrammatical", attractor_num == "singular")
```

Figure \@ref(fig:exp1AvgResponse) shows the average proportions of ‘acceptable’ responses by experimental condition for both the original experiment in @LagoEtAl2018 and our replication with unambiguous possessive marking. 
It shows that ungrammatical sentences with plural attractors are rated as acceptable more often
(M = `r printnum(exp1_cur_entry1$M)`, 
SE = `r printnum(exp1_cur_entry1$SE)`) 
than their counterparts with singular attractors 
(M=`r printnum(exp1_cur_entry2$M)`, 
SE=`r printnum(exp1_cur_entry2$SE)`).
The magnitude of the effect (`r sprintf("%0.2f", exp1_cur_entry1$M-exp1_cur_entry2$M)`) was in line with the findings reported in @LagoEtAl2018, where the difference was `r sprintf("%0.2f", lago_cur_entry1$M-lago_cur_entry2$M)`.
Accuracy rates for grammatical conditions were nearly equal
(M = `r printnum(exp1_cur_entry3$M)` and `r printnum(exp1_cur_entry4$M)`, SE = `r printnum(exp1_cur_entry3$SE)` and `r printnum(exp1_cur_entry4$SE)`, for singular and plural attractors respectively). 



```{r exp1AvgResponse, fig.height=3 ,fig.cap="Average response times for experiment 1 and experiment 2."}
print(p_avg_resp)
```

A Bayesian GLM assuming a Bernoulli distribution with a probit-link function was fit to participants' `acceptable' responses. The model's estimates and 95\% credible intervals are shown in Figure \@ref(fig:exp1ResponseModel).
<!-- They confirm the observations we stated above: the positive interaction between sentence grammaticality and attractor number is in line with a larger effect of attractor number in ungrammatical sentences.  -->  

```{r Exp1:BayesianModels, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
df_merged %<>% within(., {
  cGrammatical <- ifelse(grammatical == "grammatical", .5, -.5)
  cUngrammatical <- ifelse(grammatical == "ungrammatical", .5, -.5)
  cAttractorPlural <- ifelse(attractor_num == "plural", .5, -.5)
  cEndsInConsonant <- ifelse(experiment != "Experiment 1", .5, -.5)
  #cFreqlog_n1n2 <- scale(freqlog_n1n2)
  #cFreqlog_n1 <- scale(freqlog_n1)
  #cFreqlog_n2 <- scale(freqlog_n2)
})
df_merged_nofillers <- df_merged %>% subset(is.na(source) | source != "filler")

# ## test model parameterization using a simple GLM first
# m <- glm(ResponseYes ~ (cFreqlog_n1 + cFreqlog_n2) *
#            cEndsInConsonant * cUngrammatical * cAttractorPlural,
#          data = df_merged_nofillers,
#          family = binomial("probit"))
# summary(m)

n_chains <- 4
n_cores <- 4
n_iter <- 2000

fname_exp1_responses <- "../workspace_exp1/fit_responses"
m_responses <- brm(ResponseYes ~ cEndsInConsonant * cGrammatical * cAttractorPlural + 
                                 (cGrammatical * cAttractorPlural + 1| subject) + 
                                 (cGrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers,
                   family = bernoulli("probit"), 
                   chains = n_chains, cores = n_cores, iter = n_iter,
                   file = fname_exp1_responses)

fname_exp1_responses_exp1only <- "../workspace_exp1/fit_responses_exp1only"
m_responses_exp1only <- brm(ResponseYes ~ cGrammatical * cAttractorPlural * freqlog_n1n2 + 
                                 (cGrammatical * cAttractorPlural * freqlog_n1n2 + 1| subject) + 
                                 (cGrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers %>% subset(experiment == "Experiment 1"),
                   family = bernoulli("probit"), 
                   chains = n_chains, cores = n_cores, iter = n_iter, init_r = .1,
                   file = fname_exp1_responses_exp1only
                   )

fname_exp1_responses_Lagoonly <- "../workspace_exp1/fit_responses_lagoonly"
m_responses_Lagoonly <- brm(ResponseYes ~ cGrammatical * cAttractorPlural * freqlog_n1n2 + 
                                 (cGrammatical * cAttractorPlural * freqlog_n1n2 + 1| subject) + 
                                 (cGrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers %>% subset(experiment != "Experiment 1"),
                   family = bernoulli("probit"), 
                   chains = n_chains, cores = n_cores, iter = n_iter, init_r = .1,
                   file = fname_exp1_responses_Lagoonly)

fname_exp1_rts <- "../workspace_exp1/fit_responses_rt"
m_rts <- brm(RT ~ cEndsInConsonant * cGrammatical * cAttractorPlural * freqlog_n1n2 +
                                 (cGrammatical * cAttractorPlural * freqlog_n1n2 + 1| subject) +
                                 (cGrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers,
                   family = lognormal(),
                   chains = n_chains, cores = n_cores, iter = n_iter,
                   file = fname_exp1_rts)

model_results_table <- fixef(m_responses, summary = T, robust = F) %>% 
  as.data.frame() #%>% tibble::rownames_to_column("variables")

```

The main effect of \textit{ungrammaticality} (`r print_estimate_with_ci( m_responses, 'cUngrammatical' )`) indicates that, on average, participants were quite good at distinguishing between grammatical and ungrammatical sentences. Meanwhile, the positive interaction between \textit{ungrammaticality} and \textit{attractor number} (`r print_estimate_with_ci( m_responses, 'cUngrammatical:cAttractorPlural')`) indicated a larger effect of attractor number in ungrammatical conditions, and thus a number agreement attraction effect.
Importantly, there was no evidence for a three-way interaction between \textit{the presence of ambiguity}, \textit{ungrammaticality} and \textit{attractor number} (`r print_estimate_with_ci( m_responses, 'cEndsInConsonant:cUngrammatical:cAttractorPlural')`).

<!-- % to-do:
Importantly, even if there was an interaction with experiment, it's relatively small, so it wouldn't reduce the other interaction to 0. 

Moreover, this findings are also predicted by cue-based retrieval models \citep{engelmann2019effect, vasishth2019computational} and last rendition of marking and morphing theory by \citet{HammerlyEtAl:2019}. does it tho? especially with regards to what sol lago says: gen and morphophonology gives clues. maybe we should take a look at speeded acceptability? 
maybe this is not the perfect place to write this. -->  



```{r Exp1:ModelPlots, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
contrast_names <- c("cGrammatical" = "Grammaticality",
                    "cAttractorPlural" = "Plural Attactor",
                    "cGrammatical:cAttractorPlural" = "Grammaticality * Plural Attractor",
                    "cEndsInConsonant" = "Ambiguity",
                    "cEndsInConsonant:cGrammatical" = "Ambiguity * Grammaticality",
                    "cEndsInConsonant:cAttractorPlural" = "Ambiguity * Plural Attractor",
                    "cEndsInConsonant:cGrammatical:cAttractorPlural" = "Ambiguity * Grammaticality * Plural Attractor")

p_m_response <- 
  create_model_coefs_plot( m_responses, 
        plot_stats = T, map_names = contrast_names,
        expand_right = 2.5, expand_top = 2, x_stat_adjust = 1.1,
        x_breaks = -1:4 ) + 
        xlab("Estimate (probit)")
contrast_names_exp1 <- c("cGrammatical" = "Grammaticality",
                         "cAttractorPlural" = "Plural Attactor",
                         "freqlog_n1n2"="log Frequency: N1-N2",
                         "cGrammatical:freqlog_n1n2" = "Grammaticality * log Frequency: N1-N2",
                         "cAttractorPlural:freqlog_n1n2" = "Plural Attactor * log Frequency: N1-N2",
                         "cGrammatical:cAttractorPlural" = "Grammaticality * Plural Attractor",
                         "cGrammatical:cAttractorPlural:freqlog_n1n2" = "Grammaticality * Plural Attractor * log Frequency: N1-N2"
                        )

p_m_response_exp1 <- 
  create_model_coefs_plot( m_responses_exp1only, 
        plot_stats = T, map_names = contrast_names_exp1,
        expand_right = 2.5, expand_top = 2, x_stat_adjust = 1.1,
        x_breaks = -1:4 ) + 
        xlab("Estimate (probit)")

p_m_response_exp1 <- p_m_response_exp1 + facet_wrap(~"Experiment 1") + annotate(x=-2, xend=4, y=0, yend=0, lwd=0.25, geom="segment")

p_m_response_lago <- 
  create_model_coefs_plot( m_responses_Lagoonly, 
        plot_stats = T, map_names = contrast_names_exp1,
        expand_right = 2.5, expand_top = 2, x_stat_adjust = 1.1,
        x_breaks = -2:4 ) + 
        xlab("Estimate (probit)")

p_m_response_lago <- p_m_response_lago + facet_wrap(~"Lago et al. (2018)") + annotate(x=-2, xend=4, y=0, yend=0, lwd=0.25, geom="segment")

p_m_response_exp1_and_lago <- ggarrange(p_m_response_exp1, p_m_response_lago, ncol = 1)




```


```{r exp1ResponseModel, fig.height=3 ,fig.cap="Estimates and 95% credible intervals for the regression coefficients for the model of Experiment 1 and Lago et al. (2018)."}
suppressWarnings({
print(p_m_response + annotate(x=-3, xend=2, y=0, yend=0, lwd=0.25, geom="segment"))
})
```


```{r exp1ResponseModelSepExp1AndLago, fig.height=5  ,fig.cap="Estimates and 95% credible intervals for the regression coefficients for Experiment1 and Lago et al. (2018)."}
suppressWarnings({
print(p_m_response_exp1_and_lago)
})
```


## Discussion

In Experiment 1, we have found number attraction effects in Turkish using genitive possessive structures, as it is also attested in @LagoEtAl2018. To account for their findings, @LagoEtAl2018 assume a cue-based memory retrieval mechanism. That is, they assume that upon reaching the verb, the parser attempts to retrieve its agreement controller (the subject) using a cue-based retrieval mechanism [@LewisVasishth2005,@JagerEngelmannVasishth:2017]. The assumption is that in sentences such as \ref{item:exp1ExperimentalItems}, features such as case and number information are used to identify the agreement controller in memory. In ungrammatical sentences, when the verb bears plural agreement, no NP in memory will match both retrieval cues. However, in ungrammatical plural attractor conditions, the attractor matches one of the cues, which can lead to its erroneous retrieval on some occasions. This cannot happen in ungrammatical singular attractor conditions. This difference in the probability of erroneous retrievals is presumably what surfaced as a number agreement attraction effect, as observed in @LagoEtAl2018, and our Experiment 1.

In their work, @LagoEtAl2018 argue that the agreement attraction in genitive-possessive structures in Turkish is due to the use of genitive case as a marker of embedded subjects in Turkish, i.e. differential subject marking (DSM) properties of Turkish [@kornfilt2009dom]. They argue that the genitive case in Turkish may not provide strong cue against subjecthood due to DSM while it does in English. Following this logic, we hypothesized that the other phenomenon that gives a strong clue against the subjecthood should inhibit the illusionary dependencies as argued in @NicolEtAl:2016. One such phenomenon was present in the experimental items used in @LagoEtAl2018: the morpho-phonologic ambiguity between the accusative and the possessive case. Since they use only consonant ending heads, the marking on the head is ambiguous between the accusative and the possessive marking. Following their argumentation, participants may search for other agreement controllers than the possessive marked heads when they are engaged in shallow processing and erroneously assign head as genitive marked distractor.

Nevertheless, we found that when the possessive marker is disambiguated agreement attraction does not diminish in effect size. As seen in Figure \@ref(fig:exp1ResponseModel), we successfully replicated the findings of @LagoEtAl2018 with disambiguated head nouns. Thus, we conclude that the morpho-phonological possessive-accusative ambiguity plays no role in number attraction in Turkish.


However, there is an alternative explanation that has yet to be ruled out: task-specific strategies. We hypothesized that readers may engage in an even shallower process in the evaluation of the sentences in which readers decide on the acceptability of the sentence with a faulty state of memory. In our model, we claim that after they read the sentence readers may end up with insufficient information to reliably judge the sentence. Upon such cases, readers may end up using extremely shallow processing methods such as matching the agreement-wise unrelated but form-wise related elements. 
We present our hypothesized decision tree in Figure \@ref(fig:mptModel).


\begin{figure}[h]
    \centering
    \tiny\noindent
                      \begin{forest}
                  for tree = {
                  % nodes
                      draw, 
                      align=center,
                      minimum height=5ex,
                      minimum width=3em,
                      font=\linespread{0.84}\selectfont,
                  % tree
                      grow'=0,
                      parent anchor=east,
                      child  anchor=west,
                      s sep = 5mm,    
                      l sep = 10mm, 
                  % edge
                      edge = {semithick},
                  % level styles
                  if level = 0{}{rounded corners=2ex},
                  where n children=0{tier=level, sharp corners}{calign=edge midpoint},
                  % edge labels
                  EL/.style={edge label={node [pos=0.5, fill=white,
                                               font=\scriptsize\sffamily,
                                               inner sep=2pt] {$#1$}}
                                      }
                              }% end for tree
                  [,coordinate
                  [target\\ item,no edge
                      [recolection\\ certainity, EL=r
                          ["yes"]
                      ]
                      [recolection\\ uncertainity, EL=1-r,
                          [guess "yes", tier=L1, EL=g,
                              ["yes"]
                          ]
                          [guess "no", tier=L1, EL=1-g
                              ["no"]
                          ]
                      ]
                  ]
                  [,coordinate, no edge]
                  [target\\ item, no edge
                      [guess "yes", tier=L1, EL=g,
                              ["yes"]
                      ]
                      [guess "no", tier=L1, EL=1-g
                          ["no"]
                      ]
                   ]
                  ]
                      \end{forest} 
    \caption{Proposed multinomial processing tree of how people judge sentences in an agreement attraction task}
    \label{fig:mptModel}
\end{figure}

<!-- I will fill this one in, but I cannot find the picture of your whiteboard. -->  

The aim of our second experiment is to test whether agreement attraction in Turkish is be an instance of a \textit{form-driven processing strategy}. Assuming that readers sometimes engage in shallow processing, they may end up with insufficient information to reliably classify a sentence as (un)acceptable. In such cases, participants may choose to classify sentences with plural-agreement-bearing verbs as acceptable if they have a memory of a nominal plural morpheme in the sentence. Such a response strategy would lead to a larger number of ‘acceptable’ responses in ungrammatical plural attractor conditions than in ungrammatical singular attractor conditions even when there is no interfering noun with plural morphology but, let's say, a plural verb. 


# Experiment 2

```{r Exp2:DataWrangling, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
fname_data2 <- "../workspace_exp2/exp_data.rds"
data_exp2 <- readRDS(file = fname_data2)
fname_form <- "../workspace_exp2/exp_form.rds"
form_exp2 <- readRDS(file = fname_form)

# compute by-subject percentages of 'yes' responses, and average RTs 
avg_by_subj2 <- data_exp2 %>%
                group_by(subject, experiment, condition, 
                         grammatical, verb_num, attractor_num) %>%
                summarize(avRT = mean(RT), 
                          p_yes = mean(ResponseYes, na.rm = T), 
                          N = sum(!is.na(ResponseYes))  )

# reformat by-subject averages to a wide format
avg_by_subj_wide2 <- avg_by_subj2 %>% 
                      mutate(expcond = paste(experiment, condition, sep="_")) %>% 
                      ungroup() %>%
                      dplyr::select(-experiment, -condition, -avRT, -N,
                                    -grammatical, -verb_num, -attractor_num) %>%
                      tidyr::spread(expcond, p_yes) %>% 
                      mutate(delta_dc = AgrAttr_d - AgrAttr_c)
# identify bad participants 
bad_subjects2 <- subset(avg_by_subj_wide2, delta_dc <= 0.25 ) %>% .$subject

data_exp2_clean <- data_exp2 %>% subset(!subject %in% bad_subjects2)

data_exp2_clean %<>% filter(RT > 200 )

df_merge_exp2 <- data_exp2_clean %>% ungroup() %>% 
                      dplyr::select(source=experiment, grammatical, attractor_num, # condition,
                                    subject, item=Item,
                                    ResponseYes, RT)
df_merge_exp2$experiment <- "Experiment 2"
df_merge_exp2$grammatical %<>% dplyr::recode("gram"="grammatical", "ungram"="ungrammatical")
df_merge_exp2$attractor_num %<>% dplyr::recode("pl"="plural", "sg"="singular")
df_merge_exp2 %<>% mutate( item = sprintf("I2[%s]", as.character(item)), subject = as.character(subject) )

df_exp2_na_nofillers <- subset(df_merge_exp2, is.na(ResponseYes))

df_merge_exp1$item %<>% as.character()
df_merged2 <- dplyr::bind_rows(df_merge_exp1, df_merge_exp2)
df_merged2 %<>% mutate( subject = as.character(subject), item = as.character(item) )

df_exp2_na_nofillers <- df_merged2 %>% subset(is.na(ResponseYes) & source != "filler")
df_merged2_nonna <- df_merged2 %>% subset(!is.na(ResponseYes))

avg_clean2 <- list()
avg_clean2$resp <- df_merged2_nonna %>% 
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = ResponseYes, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = TRUE)
})

avg_clean2$rt <- df_merged2_nonna %>%
              plyr::ddply(c("experiment"), function(df) {
              df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
                           group = c("experiment", "source", "grammatical", "attractor_num"), 
                           is_proportion = FALSE)
})

# TODO: Code ResponseCorrect and re-enable
# avg_clean$rt_correct <- df_merged2_nonna %>% subset(ResponseCorrect) %>%
#               plyr::ddply(c("experiment"), function(df) {
#               df %>% se_cousineau(n_conditions = 4, subject, DV = RT, 
#                            group = c("experiment", "source", "grammatical", "attractor_num"), 
#                            is_proportion = FALSE)
# })

avg_exp2 <- avg_clean2 %>% lapply(function(df) { df %>% subset(is.na(source) | source != "filler") })
#avg_fillers <- avg_clean %>% lapply(function(df) { df %>% subset(source == "filler") })
```

```{r Exp2:PrepareTextInputs, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

exp2_cur_entry1 = avg_exp2$resp %>% filter(experiment == "Experiment 2", grammatical == "ungrammatical", attractor_num == "plural")
exp2_cur_entry2 = avg_exp2$resp %>% filter(experiment == "Experiment 2", grammatical == "ungrammatical", attractor_num == "singular")

exp2_cur_entry3 = avg_exp2$resp %>% filter(experiment == "Experiment 2", grammatical == "grammatical", attractor_num == "singular")
exp2_cur_entry4 = avg_exp2$resp %>% filter(experiment == "Experiment 2", grammatical == "grammatical", attractor_num == "plural")
```

```{r Exp2:PreparePlots, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

avg_exp2 <- avg_clean2$resp %>% subset(is.na(source) | source != "filler") %>% subset(experiment == "Experiment 2")
avg_fillers2 <- avg_clean2$resp %>% subset(source == "filler") %>% subset(experiment == "Experiment 2")

p_avg_resp2 <- ggplot(avg_exp2, aes(grammatical, M, #linetype = attractor_num, 
                                    color = attractor_num, group = attractor_num)) + 
                geom_point(position = pd) + geom_line(position = pd) + 
                facet_wrap(~experiment) +
                theme_bw() + theme( strip.background = element_rect(fill="white") ) +
                xlab("") + ylab("Percentage 'acceptable'")

p_avg_resp2 <- p_avg_resp2 + geom_errorbar(aes(ymin = M - 1.96*SE, ymax = M + 1.96*SE), width = 0.1, position = pd)
p_avg_resp2 <- p_avg_resp2 + scale_y_continuous(labels=scales::percent, limits = c(0, 1))
p_avg_resp2 <- p_avg_resp2 + scale_color_discrete(name = "Attractor Number")
```

```{r Exp2:BayesianModels, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

df_merged2 %<>% within(., {
  cGrammatical <- ifelse(grammatical == "grammatical", .5, -.5)
  cUngrammatical <- ifelse(grammatical == "ungrammatical", .5, -.5)
  cAttractorPlural <- ifelse(attractor_num == "plural", .5, -.5)
  cVerbalAttractor <- ifelse(experiment == "Experiment 2", .5, -.5)
})
df_merged_nofillers2 <- df_merged2 %>% subset(is.na(source) | source != "filler")

# ## test model parameterization using a simple GLM first
# m <- glm(ResponseYes ~ cVerbalAttractor * cUngrammatical * cAttractorPlural,
#          data = df_merged_nofillers2,
#          family = binomial("probit"))
# summary(m)

n_chains <- 4
n_cores <- 4
n_iter <- 2000


library(brms)

fname_exp2_responses <- "../workspace_exp2/fit_responses"
m_responses2 <- brm(ResponseYes ~ cVerbalAttractor * cGrammatical * cAttractorPlural + 
                                 (cGrammatical * cAttractorPlural + 1| subject) +
                                 (cGrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers2 %>% subset(!is.na(ResponseYes)),
                   family = bernoulli("probit"),
                   file = fname_exp2_responses, 
                   chains = n_chains, cores = n_cores, iter = n_iter)

fname_exp2only_responses <- "../workspace_exp2/fit_responses_exp2only"
m_responses2_exp2only <- brm(ResponseYes ~ cGrammatical * cAttractorPlural + 
                                 (cGrammatical * cAttractorPlural + 1| subject) +
                                 (cGrammatical * cAttractorPlural + 1| item),
                   data = df_merged_nofillers2 %>% 
                              subset(!is.na(ResponseYes)) %>% 
                              subset(experiment == "Experiment 2"),
                   family = bernoulli("probit"),
                   file = fname_exp2only_responses, 
                   chains = n_chains, cores = n_cores, iter = n_iter)


model2_results_table <- fixef(m_responses2, summary = T, robust = F) %>% 
  as.data.frame() #%>% tibble::rownames_to_column("variables")

```

```{r Exp2:ModelPlots, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}

contrast_names2_le <- c("cGrammatical" = "Grammaticality",
                    "cAttractorPlural" = "Plural Attactor",
                    "cVerbalAttractor" = "Verbal Attractor",
                    "cGrammatical:cAttractorPlural" = "Grammaticality * Plural Attractor",
                    "cVerbalAttractor:cGrammatical" = "Grammaticality * Verbal Attractor",
                    "cVerbalAttractor:cAttractorPlural" = "Verbal Attractor * Plural Attractor",
                    "cVerbalAttractor:cGrammatical:cAttractorPlural" = "Verbal Attractor * Grammaticality * Plural Attractor")

p_m_response_exp2 <- 
  create_model_coefs_plot( m_responses2, 
        plot_stats = T, map_names = contrast_names2_le,
        expand_right = 4.5, expand_top = 1.5, x_stat_adjust = .75,
        x_breaks = -1:4 ) + 
        xlab("Estimate (probit)")
    
p_m_response_exp2 <- p_m_response_exp2 + annotate(x=-1, xend=4, y=0, yend=0, lwd=0.25, geom="segment")

p_m_response_exp2_exp2only <- 
  create_model_coefs_plot( m_responses2_exp2only, 
        plot_stats = T, map_names = contrast_names2_le,
        expand_right = 1.5, expand_top = 1.5, x_stat_adjust = .75,
        x_breaks = -1:4 ) + 
        xlab("Estimate (probit)")
    
p_m_response_exp2only <- p_m_response_exp2_exp2only + annotate(x=-1, xend=4, y=0, yend=0, lwd=0.25, geom="segment")

```


The aim of the Experiment 2 is to control for _form-driven processing strategies_ which may be employed by the participants in the processing of Turkish number agreement. A processing mechanism that is driven by form itself, rather than the embedded linguistic features, would predict the comparable agreement attraction effects even when the attractor does not contain a possible nominal plural feature to create interference but contains a form-identical morpheme.  To this end, we utilized syncretism between nominal and verbal plural marking in Turkish. Instead of genitive marked nouns, we used the verb of a object relative clauses as in \@ref(item:exp2Items). We expect that under some conditions in which participants do not have sufficient information to rate sentences (un)acceptable, they will decide on the grammaticality of the sentence based on their memory of plural morpheme string, regardless of the feature itself. 

\begin{exe}
\ex \label{item:exp2Items}
\gll Tut-tuk-$\emptyset$/lar-(n)ı aşçı mutfak-de sürekli zıpla-dı-$\emptyset$/lar.\\
hire-\Nmlz{}-\Sg{}/\Pl{}-\Poss{} cook kitchen-\Loc{} non-stop jump-\Pst{}-\Sg{}/\Pl{}\\
\glt `The cook that they hired\textsubscript{sg/pl} jumped\textsubscript{sg/pl} in the kitchen non-stop.'
\end{exe}

_Form-driven processing strategies_ predicts that  we wanted to rule out the possibility of \textit{form-driven processing strategy}, namely participants deciding on the acceptability of a sentence using a memory of plural morpheme in the sentence when they do not have sufficient information to rate sentences (un)acceptable. 
 

## Participants

We recruited 79 undergraduate students to participate in Experiment 2 in exchange for course credit. All participants were native speakers of Turkish, with an average age of `r printnum(mean(form_exp2$Age))` (range: `r min(form_exp2$Age)` - `r max(form_exp2$Age)`). 
Experiment were carried out following the Declaration of Helsinki and the regulations concerning ethics at research in Bo\u{g}azi\c{c}i University. All participants provided informed consent prior to their participation.


## Materials

We used 40 sets of sentences like
(\ref{item:exp2ExperimentalItems}), in which we manipulated
(i) the number of the attractor, and
(ii) the number agreement on the verb. 
Unlike Experiment 1, we used the verb of a nominalized relative clause (i.e. \textit{tuttukları}) as an attractor instead of a genitive marked noun. 
We took advantage of syncretism between Turkish nominal and verbal plural marker. Both of these morphemes spells-out as \textit{-lAr}, which enables us to check whether agreement attraction in Turkish can be explained by an extremely shallow dependency parsing based on the forms of morphemes rather than linguistic features.


All sentences started with a complex subject NP like \textit{`the cook that they hired'} (\textit{tuttukları aşçı}), in which the verb of the relative clause functioned as the attractor. Because the head noun was singular in all conditions, sentences with plural verb agreement were ungrammatical.  
We have used the same verbs, and have not changed the distribution of verb types. We also utilized the same or similar adverbials in length.
Relative clauses we used in this experiment are all object relative clauses, and they are all marked with canonical \textit{-dIK} nominalizer. Since Turkish is a pro-drop language, we also dropped the subject within the embedded clause, thus ending up with a one-word object relative clause whose head is the controller of the number agreement on the matrix verb. One example set of experimental items can be seen in \ref{item:exp2ExperimentalItems}.

\begin{exe}
\ex \label{item:exp2ExperimentalItems}
\begin{xlist}

\ex \textsc{Plural Attractor, Ungrammatical (Plural Verb)}\label{item:exp2expitem-plpl}
  \gll *[Tut-tuk-lar-ı \textbf{aşcı}] mutfak-ta sürekli \textbf{zıpla-dı-lar}.\\ 
  hire-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`The cook that they hired were jumping in the kitchen non-stop.'}

\ex \textsc{Plural Attractor, Grammatical (Singular Verb)}\label{item:exp2expitem-plsg}
  \gll [Tut-tuk-lar-ı \textbf{aşcı}] mutfak-ta sürekli \textbf{zıpla-dı}.\\ 
  hire-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{pst}.\\
  \glt \textit{`The cook that they hired was jumping in the kitchen non-stop.'}

\ex \textsc{Singular Attractor, Ungrammatical (Plural Verb)}\label{item:exp2expitem-sgpl}
  \gll *[Tut-tuğ-u \textbf{aşcı}] mutfak-ta sürekli \textbf{zıpla-dı-lar}.\\ 
  hire-\textsc{nmlz}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{pst}-\textsc{pl}.\\
  \glt \textit{`The cook that they hired were jumping in the kitchen non-stop.'}

\ex \textsc{Singular Attractor, Grammatical (Singular Verb)}\label{item:exp2expitem-sgsg}
  \gll [Tut-tuğ-u \textbf{aşcı}] mutfak-ta sürekli \textbf{zıpla-fı}.\\ 
  hire-\textsc{nmlz}-\textsc{poss}  cook kitchen-\textsc{loc} non-stop  jump-\textsc{pst}.\\
  \glt \textit{`The cook that they hired was jumping in the kitchen non-stop.'}
\end{xlist}
\end{exe}

In addition to the experimental items, we used 40 filler sentences of two types, both of which starts with an object relative clause, as illustrated in (\ref{item:exp2FillerItems}). Similar to Experiment 1, our filler items included 20 grammatical sentences with an overtly plural marked verbs, and 20 ungrammatical sentences with no overt plural marking, thus singular. 
This was done in order to discourage participants from using a strategy based on verb number. 
In all of our filler sentences, the dependency between the first complex NP subject modified with an object relative clause and its verb resolved in an adverbial embedded sentence. 
In grammatical fillers, we have used intransitive verbs with a pro-dropped subject as in (\ref{item:exp2FillerItems_plural}). 
In ungrammatical fillers, we created the ungrammaticality by placing an adverbial between the bare nominal object and the verb as in (\ref{item:exp2FillerItems_singular}). 

\begin{exe}
\ex \label{item:exp2FillerItems}
\begin{xlist}

\ex \label{item:exp2FillerItems_plural} \textsc{Grammatical Filler (Plural Verb)}\\ 
  \gll Oku-t-tuk-lar-ı öğrenci başarılı ol-unca mutlu ol-du-lar.\\ 
  read-\textsc{caus}-\textsc{nmlz}-\textsc{pl}-\textsc{poss}  student successful be-\textsc{nmlz} happy be-\textsc{pst}-\textsc{pl}.\\
  \glt `When the student they sponsored become successful, they became happy.' 

\ex \label{item:exp2FillerItems_singular} \textit{Ungrammatical Filler (Singular Verb)}\\ 
  \gll *Kandır-dığ-ı adam öde-me-yince bulaşık saatlerce yıka-dı.\\ 
  trick-\textsc{nmlz}-\textsc{poss}  man pay-\textsc{neg}-\textsc{nmlz} dish for.hours clean-\textsc{pst}.\\
  \glt Intended:`When the man he tricked did not pay, he cleaned dishes for hours.'
\end{xlist}
\end{exe}

## Procedure

The experiment was run online, using the web-based platform Ibex Farm (\url{http://spellout.net/ibexfarm/}). For each participant, experiment took approximately 25 minutes to complete.
Participants were asked to provide information regarding their native language and age. They were also asked for their consent to participate in the experiment.
Prior to experimental items, participants read the instructions, and were given 9 practice items with feedback on their accuracy.
Each trial began with a blank screen for 600 ms, followed by a word-by-word RSVP presentantion of the sentence in the center of the screen, followed by an acceptability judgment. Sentences were presented in 30pt font size, and at a rate of 400 ms per word. Between each word, participants saw a blank screen for 100 ms. Participants pressed the key `P' for `\textit{acceptable}' and `Q' for `\textit{unacceptable}'.
Within instructions, they were told to provide an acceptability rating before 5,000 ms deadline. During the experiment, they were reminded to respondfaster if they did not respond within 5,000 ms.

Participants saw 40 experimental and 40 filler sentences. Experimental sentences were distributed among four different lists according to a Latin-square design. Every participant saw one version of the experiment with a specific list and one item per condition.

## Analysis

In our analysis, we used the items from Experiment 1, as well as the items from Experiment 2. this decision was made to answer our hypothesis that whether or not participants use the form of the plural suffix rather than the linguistic features. A presence of interaction between the attractor type (\textit{nominal} vs. \textit{verbal}) and the agreement attraction effect would indicate that people use the linguistic features rather than the form of the plural suffix. 

Similar to Experiment 1, we removed the data for all participants who did not exceed the threshold of 25 percentage points in 'yes' responses between the grammatical condition and the ungrammatical condition with singular attractors. As a result, we excluded `r stopifnot(length(bad_subjects2) == 1)` one participant from the Experiment 2, and `r length(bad_subjects)` participant from the Experiment 1.

We used R packages brms [@brms] and rstan [@stan] to fit Bayesian hierarchical models [e.g., @GelmanHill2007]. We aalyzed only experimental sentences, and used (i) grammaticality of the sentence, (ii) attractor number, and (iii) type of the plural suffix (i.e., experiment), as well as their interactions as predictors. 
Moreover, we used by-participant and by-item intercepts and slopes for all predictors.
Data for Experiment 2, along with our analysis scripts can be found in \url{https://github.com/utkuturk/orc-attractor_numberattraction}.

## Results

\autoref{fig:exp2AvgResponse} shows the average proportions of 'acceptable' responses by experimental conditions for Experiment 2. 
It shows that ungrammatical sentences with plural attractors are rated as acceptable 
(M = `r exp2_cur_entry1$M`, 
SE = `r exp2_cur_entry1$SE`) 
as their counterparts with singular attractors 
(M = `r exp2_cur_entry2$M`, 
SE = `r exp2_cur_entry2$SE`). The lack of effect (`r sprintf("%0.2f", exp2_cur_entry1$M-exp2_cur_entry2$M)`) compared to the magnitude of the effect in Experiment 1 (`r sprintf("%0.2f", exp2_cur_entry1$M-exp2_cur_entry2$M)`) indicates that the verbal plural morpheme does not trigger an illusionary agreement.
Accuracy rates for grammatical conditions were nearly equal
(M = `r exp2_cur_entry3$M` and `r exp2_cur_entry4$M`, 
SE = `r exp2_cur_entry3$SE` and `r exp2_cur_entry4$SE`, for singular and plural attractors respectively). 

```{r exp2AvgResponse, fig.height=3 ,fig.cap="Estimates and 95% credible intervals for the regression coefficients for Experiment 1 and Experiment 2.  Within-subject 95% confidence intervals in brackets."}
# \\cite{Cousineau:2005,Morey:2008}
print(p_avg_resp2)

```


A Bayesian GLM assuming a Bernoulli distribution with a probit-link function was fit to participants' `acceptable' responses. The model's estimates and 95\% credible intervals are shown in \@ref(fig:exp2ResponseModel). 
The main effect of \textit{ungrammaticality} (`r print_estimate_with_ci( m_responses2, 'cUngrammatical' )`) indicates that, 
on average, participants were quite good at distinguishing between grammatical and ungrammatical sentences. 
Meanwhile, there was no evidence for an interaction between \textit{ungrammaticality} and \textit{attractor number} (`r print_estimate_with_ci( m_responses2, 'cUngrammatical:cAttractorPlural')`), indicating 
a similar effect of attractor number in ungrammatical conditions compared to grammatical conditions, and thus no number agreement attraction effect.
Importantly, the negative effect between \textit{the presence of the verbal plural}, \textit{ungrammaticality} and \textit{attractor number} (`r print_estimate_with_ci( m_responses2, 'cVerbalAttractor:cUngrammatical:cAttractorPlural')`) indicated that the plural morpheme on the verb of the object relative clause lowered the agreement attraction effects.

```{r exp2ResponseModel, fig.height=3 ,fig.cap="Estimates and 95% credible intervals for the regression coefficients for a model of Experiment 1 and Experiment 2."}
print(p_m_response_exp2)

```

```{r exp2ResponseModelExp2Only, fig.cap="Estimates and 95% credible intervals for the regression coefficients for Experiment 2.", fig.height=1.5}
print(p_m_response_exp2only)

```


## Discussion

In Experiment 2, we could not find any effect of agreement attraction in the acceptability ratings of ungrammatical conditions with a verbal plural attractor. However, number agreement attractions were observed when the attractors were nominal. Even though the forms of the two plural morphemes are the same form-wise, there is a distinct difference between the results of two experiments. One of the indications of zero-effect with verbal plural morpheme is that readers do not make decisions solely based on the form of the elements. This finding contradicts our hypothesized form-driven processing strategy and supports an account of agreement attraction based on the use of abstract linguistic features, rather than mere form.

However, results may be more telling with regards to the other theories of agreement attraction. From the perspective of cue-based retrieval processes, these results tell us that the notion of feature \texttt{+plural} is more complex than previously reported. When a language have syncretic verbal and nominal plurals, it is now reasonable to say that participants distinguish even more and consider the base of the suffixes that they attach. The findings of this experiment indicate towards more fine-grained features needs to be utilized. One other possible explanation within the cue-based retrieval models can be formed around the satisfaction of a dependency. Considering our results, we can manipulate that once a feature is used for a certain representation, it cannot be used again. One can say that the agreement process is completed when the verbal plural on the attractor verb is read. In other words, since the plural morpheme on the attractor verb is not the agreement-triggering morpheme but the probe of the agreement, the retrieval mechanism should not even consider a possibility of retrieving a plural cue from the verb. This may be because either verbal plural are not encoded with \texttt{+plural} cue or they are encoded with \texttt{+plural} and an additional cue which transmits that the dependency is satisfied. This difference would mean that verbal \textit{-lAr} should not start any search for dependency resolution. In contrast to verbal \textit{-lAr}, the plural morpheme on the noun attractor is supposed to be triggering part of the agreement, not the probe. 

<!-- 

However, in Turkish embedded clauses, where genitive subjects can be seen, the number agreement works differently than the matrix level agreement. When the genitive subject of an embedded clause is marked with plural it is ungrammatical to have plural marking on the verb. This prohibition in return means that the genitive subjects should not create an expectation for a plural marked verb, which was believed to be the reason for the agreement attraction in @LagoEtAl2018.

-->  


As for the marking and morphing theories, the results of experiment 2 are completely expected. The effects founds in experiment 2 can be explained by the spreading activation. In the experiment 2 spreading activation were lower due to the distance between the verbal plural and the root note of the head subject compared to the spreading activation with genitive attractors which are closer to root node. Due to the genitive possessor's limited inner complexity and syntactic depth compared to that of relative clause constructions, marking and morphing theories would expect higher contribution from the genitive attractors to the final representation of number information. 

<!-- By depth, I mean how many root nodes between the plural item and the root node. I always understood as such. -->  

# General Discussions

We investigated the role of shallow processing in generating agreement attraction effects. We were not able to find any significant finding for the role of morphological local ambiguity (Experiment 1) and the role of form-driven processing strategies (Experiment 2). The results of experiment 1 showed us that the link between the Inhibition Hypothesis and the shallow processing explanation would not predict agreement attraction effects in Turkish. Furthermore, our results of experiment 2 also falsify our hypothesis which was based on the use of morpho-orthographic form for acceptability judgment when there is no enough information.

Our results align with the already existing theories that argue for the role of structural embedding in agreement attraction: MMT. Following the minimalist framework, I assume the following trees as in \@ref(syntax:genposs) and \@ref(syntax:orc). Since the plural containing item is embedded deeper in the tree, the verb within the object relative clause would contribute less than  the genitive marked NP. 

<!-- Utku: I do not think you assume this, that is why I used first person pronoun here. we may not include this part, or write something entirely different, but I wanted to be as clear as possible with my assumption. Because I know you are going to ask about them :D  -->  
\begin{multicols}{2}

\begin{exe}
\ex \label{syntax:genposs}
\begin{forest}
ned
[DP
  [
    [NP
    [N\\yöneticiler]
    ]
    [D\\-in]
  ]
  [
    [NP\\aşçısı]
    [D]
  ]
]
\path[fill=red] (.parent anchor) circle[radius=2pt];
\path[fill=red] (!1.child anchor) circle[radius=2pt];
\path[fill=red] (!11.child anchor) circle[radius=2pt];
\path[fill=red] (!111.child anchor) circle[radius=2pt];
\end{forest}

\ex \label{syntax:orc}
\begin{forest}
ned
[DP
  [
    [
      [pro]
      [
        [VP
          [NP\\ t\textsubscript{1}]
          [V\\Tuttukları]
        ]
        [T]
      ]
    ]
    [C]
  ]
  [
    [NP\\aşçı]
    [D]
  ]
]
\path[fill=red] (.parent anchor) circle[radius=2pt];
\path[fill=red] (!1.child anchor) circle[radius=2pt];
\path[fill=red] (!11.child anchor) circle[radius=2pt];
\path[fill=red] (!112.child anchor) circle[radius=2pt];
\path[fill=red] (!1121.south) circle[radius=2pt];
\path[fill=red] (!11212.child anchor) circle[radius=2pt];
\end{forest}
\end{exe}

\end{multicols}

<!-- utku todo: find the analysis for dp-gen-pos for turkish from aygen phd thesis. RC and the NP must be sister correct that.-->  

Additionally, our results suggest fine-tuning within the cue-based retrieval explanation. Retrieving \texttt{+plural} is not enough as shown in our experiment 2. Other pieces of information are necessary to stimulate agreement attraction effects. One possibility is retrieval only happens among the non-satisfied dependencies. Another possibility is that the base of the plural is also encoded. 

As for our hypothesized shallow processing explanation for agreement attraction, we could not provide any evidence towards it. We can say that with these structures we were not able to generate agreement attractions. 

# Conclusion

In this paper, we reported two experiments on number agreement attraction effects in Turkish. We observed number agreement attraction with nominal plural morphemes in experiment 1, but not with verbal plural morphemes in experiment 2. In Experiment 1, our findings were parallel to those of @LagoEtAl2018 with unambiguously possessive marked heads. In Experiment 2, we failed to observe number agreement attraction effects with object relative clause attractors.

Our results suggest that morpho-phonological ambiguities do not play a role in number agreement attraction in Turkish, and speakers do not use form solely in decision making processes. These findings support an agreement attraction theory which makes use of abstract linguistic features.


# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
